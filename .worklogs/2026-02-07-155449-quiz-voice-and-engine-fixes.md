# Fix quiz generator voice, engine edge case, and schema descriptions

**Date:** 2026-02-07 15:54
**Scope:** `landing/src/lib/quiz/generate-quiz.ts`, `landing/src/lib/quiz/quiz-engine.ts`, `landing/src/lib/quiz/quiz-schema.ts`, `clients/openrouter/openrouter-llm-client.ts`, `scripts/generate-one-quiz.ts`, `landing/src/lib/quiz/solid-foods-readiness.json`

## Summary
Fixed four interrelated issues: (1) quiz generator system prompt instructed warm/therapist voice instead of Steady Parent voice, (2) Zod schema `.describe()` strings reinforced the wrong voice, (3) quiz engine produced misleading shareable summaries when all domain scores tied, (4) OpenRouter client failed to resolve `$ref` schemas from `zod-to-json-schema`. Generated one test quiz (solid-foods-readiness) to verify the new prompt produces correct voice.

## Context & Problem
User identified that ALL quiz content — both LLM-generated and hand-crafted (parenting-battery) — was written in a warm, supportive therapist voice with platitudes. Root cause: the system prompt in `generate-quiz.ts` explicitly instructed "warm, non-judgmental language" and "encouraging regardless of score." The Steady Parent writing style guide (`research/seo/writing-style.md`) explicitly bans this: "Not this: 'You're not alone, and you're doing an amazing job just by being here.'" The writing style was never referenced by the generator.

Secondary issues: (a) 0% all-domains edge case showed "strongest in Energy, room to grow in Recovery" when all domains were tied at 0%; (b) schema `.describe()` fields said "should feel like a hug" and "warm, supportive tone" which the LLM reads as generation instructions.

## Decisions Made

### Rewrote generator system prompt with SP voice
- **Chose:** Replace warm/therapist voice directives with explicit Steady Parent voice rules — wry, self-deprecating, rational, direct. Added NEVER/INSTEAD lists with specific anti-patterns and examples.
- **Why:** The system prompt is the primary voice instruction. Everything flows from it. The writing-style.md already defines the voice; the prompt just wasn't using it.
- **Alternatives considered:**
  - Inject full writing-style.md into prompt — rejected because it's 220 lines and would waste context on structural rules irrelevant to quiz generation
  - Add a reference link — rejected because the LLM can't read files

### Updated schema `.describe()` strings
- **Chose:** Changed 7 schema field descriptions from warm/supportive language to direct/honest language
- **Why:** `zod-to-json-schema` embeds these descriptions in the JSON schema sent to the LLM, so they function as secondary prompt instructions. "Should feel like a hug" actively contradicts "skip the hug."
- **Fields changed:** `DomainHighContentSchema.detail`, `DomainMediumContentSchema.headline/detail`, `DomainLowContentSchema.headline/detail`, `ResultTemplateSchema.explanation/encouragement`

### Fixed 0% edge case in shareable summary
- **Chose:** Changed condition from `strongestDomain.name === weakestDomain.name` to `strongestDomain.percentage === weakestDomain.percentage`
- **Why:** When all domains tie (at any percentage), "strongest in X, room to grow in Y" is meaningless. The name-based check only caught single-domain quizzes, not tied multi-domain scores.

### Fixed OpenRouter client `$ref` resolution
- **Chose:** Added `$ref` resolution in `sanitizeJsonSchemaForOpenRouter` — if the top-level schema is a `$ref` pointing into `definitions`, resolve it before stripping
- **Why:** `zod-to-json-schema` with `.refine()` schemas produces `{ "$ref": "#/definitions/QuizData", "definitions": { "QuizData": {...} } }`. The old sanitizer stripped `definitions` and left a dangling `$ref`, causing 400 errors from OpenRouter.
- **Note:** Even with this fix, the refined schema still serializes to `{}` because `ZodEffects` from `.refine()` isn't supported by `zod-to-json-schema`. Structured output via `generateQuiz()` still doesn't work. The generation script calls the API directly without structured output and validates with Zod afterward.

### Bumped source name schema limit from 100 to 150
- **Chose:** Increased max length for `meta.sources[].name` from 100 to 150 chars
- **Why:** Academic citations like "Naylor & Morrow (2001): Developmental Readiness of Normal Full Term Infants..." are 116 chars. 100 was too tight.

### Deleted all LLM-generated quiz JSONs
- **Chose:** Confirmed the 11 deleted quiz JSONs are gone (git status showed `D` for all). Index already only registers 3 hand-crafted quizzes.
- **Why:** All generated quizzes had wrong voice. They need regeneration from scratch with the new prompt.

## Architectural Notes
- The `generateQuiz()` function in `generate-quiz.ts` has a broken structured output path (ZodEffects from `.refine()` can't be serialized by `zod-to-json-schema`). It was never actually used — the 12 quizzes were generated by agents writing JSON directly. The function's system/user prompts are correct now, but invocation must go through direct API call + Zod validation (as `scripts/generate-one-quiz.ts` demonstrates).
- The parenting-battery.json still has warm/platitude content (hand-crafted). It needs rewriting — either by hand in SP voice or by running it through the generator. This is a separate task.
- `potty-training-readiness.json` and `kindergarten-readiness.json` were generated with the old prompt and have the wrong voice. They need regeneration too.

## Information Sources
- `research/seo/writing-style.md` — the canonical voice guide that was never referenced by the generator
- `.worklogs/2026-02-06-141245-assessment-quiz-generation.md` — how the 12 quizzes were originally generated (by agents, not the function)
- `.worklogs/2026-02-06-123254-quiz-schemas-and-brainstorm.md` — schema design decisions

## Test Results
Generated `solid-foods-readiness.json` with the new prompt. Voice check:
- Zero platitudes found (automated scan for 10 banned phrases)
- Zod validation passed (after source name limit bump)
- Voice examples from output: "your baby just lunged at your sandwich like a tiny, drooly linebacker", "They track the fork from plate to mouth like a spectator at Wimbledon", "That's survivorship bias, not evidence"

## Open Questions / Future Considerations
- **parenting-battery.json** still has wrong voice — needs rewrite (hand-crafted, so can't just regenerate blindly)
- **potty-training and kindergarten quizzes** need regeneration with new prompt
- **`generateQuiz()` structured output path** is broken for refined schemas — either fix by exporting the base schema (pre-refinement) for serialization, or accept the direct-API-call pattern
- **10 remaining assessment quizzes** need generation with new prompt
- **10 identity quizzes (Type B)** haven't started — different schema, different generator needed

## Key Files for Context
- `landing/src/lib/quiz/generate-quiz.ts` — generator with updated voice prompt
- `landing/src/lib/quiz/quiz-schema.ts` — Zod schemas with updated `.describe()` strings
- `landing/src/lib/quiz/quiz-engine.ts` — engine with fixed tie-handling
- `research/seo/writing-style.md` — canonical voice guide
- `scripts/generate-one-quiz.ts` — working generation script (bypasses broken structured output)
- `clients/openrouter/openrouter-llm-client.ts` — fixed `$ref` resolution
- `.worklogs/2026-02-06-141245-assessment-quiz-generation.md` — context on original generation approach

## Next Steps / Continuation Plan
1. Regenerate potty-training-readiness and kindergarten-readiness with new prompt (use `scripts/generate-one-quiz.ts` pattern)
2. Rewrite parenting-battery.json in SP voice — either hand-craft or pipe through generator with hand-crafted questions preserved
3. Batch-generate remaining 10 assessment quizzes with new prompt
4. Consider fixing `generateQuiz()` structured output by exporting pre-refinement base schema alongside the refined version
5. Begin identity quiz (Type B) work — separate schema, separate generator
